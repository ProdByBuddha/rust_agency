//! Supervisor
//! 
//! The central orchestrator that coordinates multiple agents.

use anyhow::Result;
use ollama_rs::Ollama;
use std::sync::Arc;
use tokio::sync::{Semaphore, Mutex, mpsc};
use std::collections::VecDeque;
use tracing::{info, warn};
use futures_util::future::join_all;

use crate::agent::{ReActAgent, AgentType, AgentConfig, LLMCache, LLMProvider, AutonomousMachine, AgentResponse, OllamaProvider, AgentResult, AgentError};
use crate::agent::rl::ExperienceBuffer;
use crate::memory::{Memory, EpisodicMemory};
use crate::emit_event;
use crate::orchestrator::{
    Plan, Router, SessionManager, 
    DesignRationaleRecord, Publication,
    Objective, profile::AgencyProfile,
    aggregation::{Candidate, Gamma, RewardModel},
    ResultPortfolio, ScaleProfile, AgencyEvent
};
use pai_core::{HookManager, HookEvent, HookEventType};

pub struct SupervisorResult {
    pub answer: String,
    pub success: bool,
    pub plan: Option<Plan>,
    pub reflections: Vec<String>,
    pub publication: Option<Publication>,
    pub pending_approval: Option<crate::safety::ApprovalRequest>,
    pub has_followup: bool,
}

pub struct Supervisor {
    pub provider: Arc<dyn LLMProvider>,
    pub tools: Arc<crate::tools::ToolRegistry>,
    pub memory: Option<Arc<dyn Memory>>,
    pub session: Option<SessionManager>,
    pub history_manager: Arc<crate::memory::HistoryManager>,
    pub max_retries: usize,
    pub cache: Arc<LLMCache>,
    pub hw_lock: Arc<tokio::sync::Mutex<()>>,
    pub safety: Arc<Mutex<crate::safety::SafetyGuard>>,
    pub role_algebra: crate::orchestrator::RoleAlgebra,
    pub concurrency_limit: Arc<Semaphore>,
    pub episodic_memory: Arc<tokio::sync::Mutex<EpisodicMemory>>,
    pub profile: AgencyProfile,
    pub reward_model: Option<Arc<dyn RewardModel>>,
    pub experience_buffer: Arc<tokio::sync::Mutex<ExperienceBuffer>>,
    /// Active steering channels for running agents
    pub active_steer_txs: Arc<Mutex<Vec<mpsc::Sender<String>>>>,
    /// Queued messages for follow-up turns
    pub followup_queue: Arc<Mutex<VecDeque<String>>>,
    /// PAI Pure Rust Hook Manager
    pub pai_hooks: Arc<HookManager>,
    /// PAI Tiered Memory Manager
    pub pai_memory: Arc<pai_core::memory::TieredMemoryManager>,
    /// PAI Recovery Journal
    pub recovery: Arc<pai_core::recovery::RecoveryJournal>,
}

impl Supervisor {
    pub fn new(ollama: Ollama, tools: Arc<crate::tools::ToolRegistry>) -> Self {
        let provider = Arc::new(OllamaProvider::new(ollama));
        Self::new_with_provider(provider, tools)
    }

    pub fn new_with_provider(provider: Arc<dyn LLMProvider>, tools: Arc<crate::tools::ToolRegistry>) -> Self {
        Self {
            hw_lock: provider.get_lock(),
            provider,
            tools,
            memory: None,
            session: None,
            history_manager: Arc::new(crate::memory::HistoryManager::new(crate::memory::HistoryManager::default_path(), Some(10 * 1024 * 1024))),
            max_retries: 2,
            cache: Arc::new(LLMCache::new()),
            safety: Arc::new(Mutex::new(crate::safety::SafetyGuard::new())),
            role_algebra: crate::orchestrator::RoleAlgebra::new(),
            concurrency_limit: Arc::new(Semaphore::new(4)),
            episodic_memory: Arc::new(tokio::sync::Mutex::new(EpisodicMemory::default())),
            profile: AgencyProfile::default(),
            reward_model: None,
            experience_buffer: Arc::new(tokio::sync::Mutex::new(ExperienceBuffer::new(100))),
            active_steer_txs: Arc::new(Mutex::new(Vec::new())),
            followup_queue: Arc::new(Mutex::new(VecDeque::new())),
            pai_hooks: {
                let mut hm = HookManager::new();
                hm.register(Arc::new(pai_core::safety::SecurityValidator::new()));
                hm.register(Arc::new(pai_core::hooks::LoggerHook));
                Arc::new(hm)
            },
            pai_memory: {
                let pai_dir = std::env::var("PAI_DIR").unwrap_or_else(|_| {
                    let home = std::env::var("HOME").unwrap_or_else(|_| std::env::temp_dir().to_string_lossy().to_string());
                    format!("{}/.config/pai", home)
                });
                Arc::new(pai_core::memory::TieredMemoryManager::new(std::path::PathBuf::from(pai_dir)))
            },
            recovery: {
                let pai_dir = std::env::var("PAI_DIR").unwrap_or_else(|_| {
                    let home = std::env::var("HOME").unwrap_or_else(|_| std::env::temp_dir().to_string_lossy().to_string());
                    format!("{}/.config/pai", home)
                });
                Arc::new(pai_core::recovery::RecoveryJournal::new(std::path::PathBuf::from(pai_dir)))
            },
        }
    }

    /// Interrupt all active agents with a steering message
    pub async fn steer(&self, message: impl Into<String>) -> Result<()> {
        let msg = message.into();
        let txs = self.active_steer_txs.lock().await;
        for tx in txs.iter() {
            let _ = tx.send(msg.clone()).await;
        }
        Ok(())
    }

    /// Queue a message to be processed after the current turn
    pub async fn enqueue_followup(&self, message: impl Into<String>) {
        self.followup_queue.lock().await.push_back(message.into());
    }

    pub fn with_experience_buffer(mut self, buffer: Arc<tokio::sync::Mutex<ExperienceBuffer>>) -> Self {
        self.experience_buffer = buffer;
        self
    }

    pub fn with_reward_model(mut self, model: Arc<dyn RewardModel>) -> Self {
        self.reward_model = Some(model);
        self
    }

    pub fn with_episodic_memory(mut self, memory: Arc<tokio::sync::Mutex<EpisodicMemory>>) -> Self {
        self.episodic_memory = memory;
        self
    }

    pub fn with_provider(mut self, provider: Arc<dyn LLMProvider>) -> Self {
        self.provider = provider;
        self
    }

    pub fn with_memory(mut self, memory: Arc<dyn Memory>) -> Self {
        self.memory = Some(memory);
        self
    }

    pub fn with_session(mut self, session: SessionManager) -> Self {
        self.session = Some(session);
        self
    }

    pub fn with_max_retries(mut self, retries: usize) -> Self {
        self.max_retries = retries;
        self
    }

    pub fn with_profile(mut self, profile: AgencyProfile) -> Self {
        self.profile = profile;
        self
    }

    pub async fn load_session(&mut self) -> Result<()> {
        if let Some(ref mut sm) = self.session {
            let state = sm.load().await?;
            let mut mem = self.episodic_memory.lock().await;
            *mem = state.episodic_memory;
            self.safety.lock().await.reset();
        }
        Ok(())
    }

    pub async fn conversation_history(&self) -> String {
        self.episodic_memory.lock().await.format_for_prompt()
    }

    pub async fn clear_history(&mut self) -> Result<()> {
        self.episodic_memory.lock().await.clear();
        if let Some(ref mut sm) = self.session {
            sm.clear().await?;
        }
        Ok(())
    }

    fn create_cached_provider(&self) -> Arc<dyn LLMProvider> {
        Arc::new(crate::agent::CachedProvider::new(
            self.provider.clone(),
            self.cache.clone()
        ))
    }

    #[tracing::instrument(skip(self, query), fields(query_len = query.len()))]
    pub async fn handle(&mut self, query: &str) -> AgentResult<SupervisorResult> {
        let _work_start_time = std::time::Instant::now();
        
        let session_id = uuid::Uuid::new_v4().to_string();

        // PAI: Trigger and LOG SessionStart Event
        let mut start_event = HookEvent {
            event_type: HookEventType::SessionStart,
            session_id: session_id.clone(),
            payload: serde_json::json!({ "query": query }),
            timestamp: chrono::Utc::now(),
        };
        pai_core::enrichment::EnrichmentEngine::enrich(&mut start_event);
        let _ = self.pai_hooks.trigger(&start_event).await.map_err(|e| AgentError::Pai(e.to_string()))?;
        let _ = self.pai_memory.log_event(&start_event);

        emit_event!(AgencyEvent::TurnStarted { 
            agent: "Supervisor".to_string(), 
            model: "Router".to_string() 
        });
        let _ = self.history_manager.append(&session_id, "user", None, query).await.map_err(|e| AgentError::Io(std::io::Error::new(std::io::ErrorKind::Other, e.to_string())))?;

        // SOTA: High-Fidelity Context Compaction (pi-mono-inspired)
        {
            let mut memory = self.episodic_memory.lock().await;
            let _ = crate::memory::compactor::ContextCompactor::compact_if_needed(
                &mut memory,
                self.provider.clone(),
                &self.profile,
                3200 // Threshold: 80% of 4k window
            ).await;
        }

        let mut full_context = String::new();
        let chatml = self.episodic_memory.lock().await.format_as_chatml();
        full_context.push_str(&chatml);
        full_context.push_str("\n\n");

        // SOTA: Concurrent Pre-processing (FPF Principle: Minimize Latency)
        // Perform memory search, agent routing, and project context discovery in parallel.
        let memory_search_task = async {
            if let Some(ref memory) = self.memory {
                match memory.search(query, 3, None, None).await {
                    Ok(relevant) if !relevant.is_empty() => {
                        let mut ctx = String::from("<|im_start|>system\nRelevant Memory:\n");
                        for entry in relevant {
                            ctx.push_str(&format!("- {}\n", entry.content));
                        }
                        ctx.push_str("<|im_end|>\n");
                        Some(ctx)
                    },
                    _ => None
                }
            } else {
                None
            }
        };

        let router_task = async {
            let router = Router::new_with_provider(self.provider.clone());
            router.route(query, Some(8.0)).await
        };

        let project_context_task = async {
            match crate::orchestrator::context::ContextLoader::load_project_context().await {
                Ok(context) if !context.is_empty() => {
                    let mut ctx = String::from("<|im_start|>system\nProject Context (discovered recursively):\n");
                    ctx.push_str(&context);
                    ctx.push_str("<|im_end|>\n");
                    Some(ctx)
                },
                _ => None
            }
        };

        let (memory_ctx, routing_result, project_ctx) = tokio::join!(memory_search_task, router_task, project_context_task);
        let routing_decision = routing_result.map_err(|e| AgentError::Execution(e.to_string()))?;

        if let Some(ctx) = project_ctx {
            full_context.push_str(&ctx);
        }

        if let Some(ctx) = memory_ctx {
            full_context.push_str(&ctx);
        }
        
        info!("Routing decision: {:?}", routing_decision.candidate_agents);

        // SOTA: Optimal Information Selection (Bennouna et al., 2025)
        // Identify directions of uncertainty that matter for the decision (plan) 
        // and resolve them with minimal queries before execution.
        if routing_decision.reasoning_required {
            let selector = crate::orchestrator::optimal_info::OptimalInfoSelector::new(
                self.provider.clone(),
                routing_decision.scale.target_model.clone()
            );
            
            if let Ok(queries) = selector.select_minimal_queries(query, "Direct Execution Plan").await {
                for q in queries {
                    let _ = self.provider.notify(&format!("üîç Resolving Uncertainty: {}", q.description)).await;
                    // Execute query as a lightweight system prompt injection
                    // In a real implementation, we would run a one-off tool call here.
                    full_context.push_str(&format!("\n<|im_start|>system\nVerified Assumption ({}): {}\n<|im_end|>\n", q.description, q.tool_call));
                }
            }
        }

        let mut current_scale = routing_decision.scale.clone();
        let mut final_res: Option<AgentResponse> = None;
        let mut final_performer = String::new();
        let final_routing = routing_decision.clone();
        let mut final_winner_idx = 0;

        // SOTA: Escalation Loop (FPF Principle C.18.2)
        // If execution fails, escalate to a stronger model and retry.
        for attempt in 0..3 {
            if attempt > 0 {
                let _ = self.provider.notify(&format!("\n‚ö†Ô∏è Task failed with {}. Escalating to next intelligence tier...\n", current_scale.target_model)).await;
                let next_class = current_scale.class.escalate();
                if next_class == current_scale.class && attempt > 0 {
                    break; // Already at intelligence ceiling
                }
                current_scale = ScaleProfile::new_with_class(next_class, 8.0); // Use class override
            }

            let mut portfolio = ResultPortfolio::default();
            let mut execution_tasks = Vec::new();
            
            for &agent_type in &final_routing.candidate_agents {
                let mut config = AgentConfig::new(agent_type, &self.profile);
                
                // SOTA: Agent-specific model overrides
                config.model = if agent_type == AgentType::Coder {
                    let registry_file = std::fs::File::open("agency_models.json").ok();
                    let coder_model = registry_file.and_then(|f| {
                        let v: serde_json::Value = serde_json::from_reader(f).ok()?;
                        v["defaults"]["coder"].as_str().map(|s| s.to_string())
                    });
                    coder_model.unwrap_or_else(|| current_scale.target_model.clone())
                } else {
                    current_scale.target_model.clone()
                };

                config.reasoning_enabled = final_routing.reasoning_required;
                let _ = self.provider.notify(&format!("STATE:MODEL:{}", config.model)).await;
                
                let provider = self.create_cached_provider();
                let query_owned = query.to_string();
                let context_owned = full_context.clone();
                let semaphore = self.concurrency_limit.clone();
                let tools = self.tools.clone();
                let memory = self.memory.clone();
                let safety = self.safety.clone();
                let hooks = self.pai_hooks.clone();
                let pai_mem = self.pai_memory.clone();
                let recovery = self.recovery.clone();
                
                let (steer_tx, steer_rx) = mpsc::channel(10);
                self.active_steer_txs.lock().await.push(steer_tx);

                execution_tasks.push(tokio::spawn(async move {
                    let _permit = semaphore.acquire().await.ok();
                    let mut agent = ReActAgent::new_with_provider(provider, config, tools)
                        .with_hooks(hooks)
                        .with_memory_manager(pai_mem)
                        .with_recovery(recovery);
                    if let Some(ref memory) = memory { agent = agent.with_memory(memory.clone()); }
                    agent = agent.with_safety(safety);
                    agent.execute_with_steering(&query_owned, Some(&context_owned), Some(steer_rx)).await
                }));
            }

            let task_results = join_all(execution_tasks).await;
            self.active_steer_txs.lock().await.clear();
            let mut responses = Vec::new();

            for (i, tr) in task_results.into_iter().enumerate() {
                let agent_type = final_routing.candidate_agents[i];
                match tr {
                    Ok(Ok(res)) => {
                        portfolio.candidates.push(Candidate {
                            agent_id: format!("{:?}", agent_type),
                            answer: res.answer.clone(),
                            quality_score: if res.success { 0.9 } else { 0.1 },
                            risk_score: 0.1,
                            cost_tokens: res.cost_tokens,
                            assurance: crate::orchestrator::AssuranceLevel::L1,
                            reward_score: None,
                        });
                        responses.push(res);
                    },
                    _ => warn!("Agent execution failed for {:?}", agent_type),
                }
            }

            // SOTA: RLM Reward Scoring (G.5)
            if let Some(ref rm) = self.reward_model {
                if !portfolio.candidates.is_empty() {
                    let _ = self.provider.notify("STATE:RLM:SCORING").await;
                    if let Ok(scores) = rm.score(query, &portfolio.candidates).await {
                        let scores: Vec<f32> = scores;
                        for (i, score) in scores.into_iter().enumerate() {
                            portfolio.candidates[i].reward_score = Some(score);
                        }
                    }
                }
            }

            if !responses.is_empty() {
                let winner_idx = Gamma::select_pareto_winner(&portfolio).unwrap_or(0);
                let winner_res = responses[winner_idx].clone();
                final_winner_idx = winner_idx;
                
                if winner_res.success {
                    final_res = Some(winner_res);
                    final_performer = format!("{:?}", final_routing.candidate_agents[winner_idx]);
                    break;
                } else if winner_res.pending_approval.is_some() {
                    // HITL Pause
                    final_res = Some(winner_res);
                    final_performer = format!("{:?}", final_routing.candidate_agents[winner_idx]);
                    break; 
                } else {
                    // All candidates in this tier failed, continue loop to escalate
                    final_res = Some(winner_res);
                    final_performer = format!("{:?}", final_routing.candidate_agents[winner_idx]);
                }
            }
        }

        let final_res = final_res.ok_or_else(|| AgentError::Execution("All execution attempts and escalations failed".to_string()))?;
        
        let mut work = crate::orchestrator::WorkRecord::new(
            "DirectTask".to_string(), 
            format!("{:?}", final_routing.candidate_agents)
        );
        work.performer_role = final_performer.clone();
        work.trace = final_res.steps.clone();
        work.complete(final_res.success, crate::orchestrator::AssuranceLevel::L1);

        let mut publication = Publication::project(
            final_res.answer.clone(), 
            &work, 
            current_scale.clone(),
            None, 
            None, 
            None
        ).with_mvpk(final_res.thought.clone(), final_res.reliability)
         .with_approval(final_res.pending_approval.clone());
        
        publication.rationale = Some(DesignRationaleRecord::new(
            "Supervisor", 
            "Routed", 
            format!("Selected candidate {} based on Pareto logic", final_winner_idx)
        ));

        // Only add to memory if it's NOT a pending approval
        if final_res.pending_approval.is_none() {
            self.episodic_memory.lock().await.add_assistant(&final_res.answer, Some(work.performer_role.clone()));
            
            // SOTA: Long-term History Persistence (codex-inspired)
            let _ = self.history_manager.append(&session_id, "assistant", Some(&final_performer), &final_res.answer).await.map_err(|e| AgentError::Io(std::io::Error::new(std::io::ErrorKind::Other, e.to_string())))?;

            if let Some(ref sm) = self.session {
                let mem = self.episodic_memory.lock().await;
                sm.save(&mem, None).await.map_err(|e| AgentError::Io(std::io::Error::new(std::io::ErrorKind::Other, e.to_string())))?;
            }
        }

        Ok(SupervisorResult {
            answer: final_res.answer,
            success: final_res.success,
            plan: None,
            reflections: vec![format!("Classified as {:?}", routing_decision.scale.class)],
            publication: Some(publication),
            pending_approval: final_res.pending_approval,
            has_followup: !self.followup_queue.lock().await.is_empty(),
        })
    }

    pub async fn run_autonomous(&mut self, goal: &str) -> AgentResult<SupervisorResult> {
        let provider = self.create_cached_provider();
        let objective = Objective::new(goal);
        let mut machine = AutonomousMachine::new_with_provider(provider.clone(), self.tools.clone(), &self.profile, objective);
        machine = machine.with_provider(provider);
        
        let mut last_res = AgentResponse::failure("Autonomous loop failed to start", Vec::new(), AgentType::Coder);
        for i in 0..5 {
            info!("Autonomous iteration {}/5", i + 1);
            match machine.run_iteration().await {
                Ok(res) => {
                    let success = res.success;
                    last_res = res;
                    if success { break; }
                },
                Err(e) => {
                    warn!("Autonomous iteration failed: {}", e);
                    break;
                }
            }
        }

        let mut work = crate::orchestrator::WorkRecord::new("Autonomous".to_string(), "Machine".to_string());
        work.trace = last_res.steps.clone();
        work.complete(last_res.success, crate::orchestrator::AssuranceLevel::L2);
        
        let heavy_profile = crate::orchestrator::ScaleProfile::new(0.9, 8.0);
        let publication = Publication::project(
            last_res.answer.clone(), 
            &work, 
            heavy_profile, 
            None, 
            None, 
            None
        ).with_mvpk(last_res.thought.clone(), last_res.reliability);
        
        Ok(SupervisorResult {
            answer: last_res.answer,
            success: last_res.success,
            plan: None,
            reflections: vec![],
            publication: Some(publication),
            pending_approval: None,
            has_followup: false,
        })
    }
}